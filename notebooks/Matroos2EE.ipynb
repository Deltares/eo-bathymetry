{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterlevel stations\n",
    "Convert data from http://matroos.deltares.nl/timeseries/start/ (noos output) into a format that can be used in Google Fusiontable\n",
    "* Terschelling Noordzee (53.443625°N, 5.333456°E)\n",
    "* Delfzijl (53.327481°N,6.933787°E)\n",
    "* Nes (53.431108°N, 5.760944°E)\n",
    "* Harlingen (53.176742°N, 5.409777°E)\n",
    "* Haringvliet 10 (51.863753°N, 3.860380°E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSVforFusionTable():\n",
    "    # Here keeping the source of Gerben's fnc.\n",
    "    stations = ['Terschelling','Delfzijl','Haringvliet']\n",
    "\n",
    "    for station in stations:\n",
    "        print (station)\n",
    "        df = pd.read_csv(r'D:\\hagenaar\\Documents\\EMODNET\\GLOSSISgrid\\ObservedWaterlevel' + str(station) + '.txt', \n",
    "                         skiprows=13, delimiter='  ', names=['time','waterlevel'])\n",
    "\n",
    "        df['time'] = pd.to_datetime(df['time'], yearfirst=True, format='%Y%m%d%H%M')\n",
    "        df.set_index('time', inplace=True)\n",
    "        df['waterlevel'][df['waterlevel'].isnull()] = np.nan\n",
    "        df['waterlevel'][df['waterlevel'] == 9999999] # missing value\n",
    "        df.dropna(inplace=True)\n",
    "        df.to_csv(r'D:\\hagenaar\\Documents\\EMODNET\\GLOSSISgrid\\ObservedWaterlevel' + str(station) + 'MODIFIED.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve data from $\\texttt{Matroos}$, but it works with indexes at the moment. By visiting the website and looking at the request, you read the code and perform the request, so that you do not need to download any file. Btw., pay attention to the printed header later in the loop, so that you are sure you are reading the right timeseries...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listbuoys = {'terschelling noordzee': 297, 'harlingen': 6, 'nes': 321, 'delfzij': 1, 'haringvliet 10': 64}\n",
    "\n",
    "t0 = datetime.datetime(2015, 1, 1)\n",
    "tf = datetime.datetime(2018, 1, 1)\n",
    "\n",
    "tnow = datetime.datetime.now().isoformat().replace('T','+')\n",
    "tstart = t0.isoformat().replace('T','+') # start time\n",
    "tend = tf.isoformat().replace('T','+') # end time\n",
    "\n",
    "# function for subsequent lambda function\n",
    "def df_get_values(value, default):\n",
    "    if len(value.split())==2:\n",
    "        v = value.split()[1]\n",
    "    else:\n",
    "        v = default\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terschelling noordzee - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "terschelling noordzee - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "terschelling noordzee - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "terschelling noordzee - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "terschelling noordzee - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "terschelling noordzee - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "terschelling noordzee - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "terschelling noordzee - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "terschelling noordzee - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "terschelling noordzee - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "terschelling noordzee - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "terschelling noordzee - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "harlingen - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "harlingen - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "harlingen - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "harlingen - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "harlingen - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "harlingen - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "harlingen - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "harlingen - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "harlingen - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "harlingen - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "harlingen - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "harlingen - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "nes - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "nes - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "nes - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "nes - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "nes - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "nes - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "nes - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "nes - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "nes - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "nes - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "nes - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "nes - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "delfzij - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "delfzij - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "delfzij - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "delfzij - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "delfzij - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "delfzij - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "delfzij - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "delfzij - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "delfzij - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "delfzij - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "delfzij - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "delfzij - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "haringvliet 10 - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "haringvliet 10 - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "haringvliet 10 - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "haringvliet 10 - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "haringvliet 10 - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "haringvliet 10 - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "haringvliet 10 - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "haringvliet 10 - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "haringvliet 10 - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "haringvliet 10 - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "haringvliet 10 - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "haringvliet 10 - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n"
     ]
    }
   ],
   "source": [
    "cc = {}\n",
    "\n",
    "# This could take several minutes, make it year by year to improve performance.\n",
    "\n",
    "for loc, loc_id0 in listbuoys.items():  # get water level signal for each buoy\n",
    "    c_df_tot = pd.DataFrame() # empty db\n",
    "    ti_dum = te_dum = t0\n",
    "    while ti_dum<tf:\n",
    "        te_dum = ti_dum + relativedelta(months=3) # add 3months\n",
    "        \n",
    "        # reconvert before request\n",
    "        ti_dum_text = ti_dum.isoformat().replace('T','+')\n",
    "        te_dum_text = te_dum.isoformat().replace('T','+')\n",
    "        \n",
    "        # in the following template,  loc_id0 is the location, source_newid0 is the \"observed\" type of source\n",
    "        additional_params = \"colors0=blue&localtime_offset=0&numser=1&old_unit_id0=1&oldlock_colors0=&oldlock_loc_id0=1&oldlock_source_newid0=1&oldlock_unit_id0=1&prealert=0&source_id0=10\"\n",
    "        url = (\"http://matroos.deltares.nl/timeseries/start/series.php?\"\n",
    "                            \"loc_id0=\" + str(loc_id0) + \"&\" # this is the location of the buoy\n",
    "                            \"source_newid0=10&\" # this is the source \"observed\"\n",
    "                            \"submit=Submit&\"\n",
    "                            \"tcurrent=\" + tnow + \"&\"\n",
    "                            \"tcurrent_new=\" + tnow + \"&\"\n",
    "                            \"tstart=\" + ti_dum_text + \"&\"\n",
    "                            \"tstop=\" + te_dum_text + \"&\"\n",
    "                            \"type=noos&\"\n",
    "                            \"unit_id0=1&\"\n",
    "                            \"alarm=0&\" # additional parameters from now on\n",
    "                            + additional_params)\n",
    "\n",
    "        r = requests.get(url).content\n",
    "        c = pd.read_csv(io.StringIO(r.decode('utf-8')),sep='\\t', header=0)\n",
    "        c_head = c[0:11]\n",
    "        # print(c_head[4:6]+'\\n') # query location, if needed\n",
    "        print(loc + ' - ' + 'from ' + ti_dum_text + ' to ' + te_dum_text)\n",
    "        c_cont = c[12:].reset_index(drop=True) # reset index\n",
    "\n",
    "        # get time and z from df\n",
    "        c_t = c_cont.applymap(lambda x: datetime.datetime(\n",
    "            int(x.split()[0][0:4]),\n",
    "            int(x.split()[0][4:6]),\n",
    "            int(x.split()[0][6:8]),\n",
    "            int(x.split()[0][8:10]),\n",
    "            int(x.split()[0][10:12])))\n",
    "        c_t.columns = ['Time']\n",
    "\n",
    "        c_z = c_cont.applymap(lambda x: df_get_values(x,np.NaN))\n",
    "        c_z.columns = ['WaterLevel']\n",
    "\n",
    "        c_df = c_t.join(c_z)\n",
    "        c_df_tot = c_df_tot.append(c_df)\n",
    "        \n",
    "        ti_dum = te_dum\n",
    "        \n",
    "    # dictionary of Dataframes\n",
    "    cc[loc] = c_df_tot # you can save it anywhere from here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dict of df's into several files [per location], csv format.\n",
    "for dfll_t, dfll_v in cc.items():\n",
    "    dfll_v.to_csv(os.path.join(PATH,dfll_t.replace(' ','_'))+'.csv', sep=',', index=False, na_rep='NaN')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterlevel from Zuno Model\n",
    "Convert data from http://matroos.deltares.nl/maps2d/start/ into a format that can be used later on.\n",
    "\n",
    "* dd zuno-v4 hirlam kf. Pick subarea in Wadden Sea (5.0048,53.1737,5.7354,53.5115)\n",
    "* dd zuno-v4 hirlam kf. Pick subarea in Western Scheldt (3.2484,51.3784,3.9817,51.7625)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = {'waddenSea': [5.0048, 53.1737, 5.7354, 53.5115], 'westernScheldt': [3.2484, 51.3784, 3.9817, 51.7625]}\n",
    "\n",
    "modelname = 'dcsmv6_zunov4_zuno_kf_hirlam'\n",
    "\n",
    "t0_N = datetime.datetime(2017, 9, 3, 10, 50, 0)\n",
    "t0_S = datetime.datetime(2016, 9, 8, 10, 50, 0)\n",
    "\n",
    "tf_N = t0_N + datetime.timedelta(minutes = 10)\n",
    "tf_S = t0_S + datetime.timedelta(minutes = 10)\n",
    "\n",
    "tnow = datetime.datetime.now().isoformat().replace('T','+')\n",
    "tstart_N = t0_N.isoformat().replace('-','').replace('T','').replace(':','') # start time\n",
    "tstart_S = t0_S.isoformat().replace('-','').replace('T','').replace(':','') # start time\n",
    "tend_N = tf_N.isoformat().replace('-','').replace('T','').replace(':','') # end time\n",
    "tend_S = tf_S.isoformat().replace('-','').replace('T','').replace(':','') # end time\n",
    "\n",
    "tstart = [tstart_N, tstart_S]\n",
    "tend = [tend_N, tend_S]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://matroos.deltares.nl/direct/get_subgrid_ascii.php?source=dcsmv6_zunov4_zuno_kf_hirlam&unit=SEP&tstart=20170903105000&tstop=20170903110000&xmin=5.0048&xmax=5.7354&ymin=53.1737&ymax=53.5115&coordsys=wgs84\n",
      "waddenSea - from 2017-09-03+10:50:00 to 2017-09-03+11:00:00\n",
      "http://matroos.deltares.nl/direct/get_subgrid_ascii.php?source=dcsmv6_zunov4_zuno_kf_hirlam&unit=SEP&tstart=20160908105000&tstop=20160908110000&xmin=3.2484&xmax=3.9817&ymin=51.3784&ymax=51.7625&coordsys=wgs84\n",
      "westernScheldt - from 2017-09-03+10:50:00 to 2017-09-03+11:00:00\n"
     ]
    }
   ],
   "source": [
    "# This could take several minutes. A single year weights TBs' thus not recommended.\n",
    "\n",
    "cc = 0\n",
    "for bboxloc, bboxloc_id0 in bbox.items():  # get water level signal for each buoy\n",
    "    c_df_tot = pd.DataFrame() # empty db\n",
    "\n",
    "    additional_params = \"\"\n",
    "    url = (\"http://matroos.deltares.nl/direct/get_subgrid_ascii.php?\"\n",
    "                        \"source=\" + modelname + \"&\"  # this is the model name\n",
    "                        \"unit=SEP&\" \n",
    "                        \"tstart=\" + tstart[cc] + \"&\"\n",
    "                        \"tstop=\" + tend[cc] + \"&\"\n",
    "                        \"xmin=\" + str(bboxloc_id0[0]) + \"&\"\n",
    "                        \"xmax=\" + str(bboxloc_id0[2]) + \"&\"\n",
    "                        \"ymin=\" + str(bboxloc_id0[1]) + \"&\"\n",
    "                        \"ymax=\" + str(bboxloc_id0[3]) + \"&\"\n",
    "                        \"coordsys=wgs84\"\n",
    "                        + additional_params)\n",
    "    \n",
    "    print(url)\n",
    "    r = requests.get(url).content\n",
    "    c = pd.read_csv(io.StringIO(r.decode('utf-8')),sep='\\t', header=0)\n",
    "\n",
    "    print(bboxloc + ' - ' + 'from ' + ti_dum_text + ' to ' + te_dum_text)\n",
    "\n",
    "    # df of file - # you can save it anywhere from here.\n",
    "    c.to_csv(os.path.join(PATH,bboxloc)+'.csv', sep=',', index=False, na_rep='NaN')\n",
    "    \n",
    "    cc += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dict of df's into several files [per location], csv format.\n",
    "#for dfll_t, dfll_v in cc.items():\n",
    "#    dfll_v.to_csv(os.path.join(PATH,dfll_t.replace(' ','_'))+'.csv', sep=',', index=False, na_rep='NaN')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
